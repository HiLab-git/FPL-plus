[dataset]
# tensor type (float or double)
tensor_type = float
supervise_type = noisy_label
task_type = seg
root_dir  = /
train_csv = config_dual/data_vs/t1_train_pl100.csv
valid_csv = config_dual/data_vs/t1_valid.csv
test_csv  = config_dual/data_vs/t1_test.csv

train_batch_size = 4

# data transforms
train_transform = [NormalizeWithMeanStd,Pad,RandomCrop, RandomFlip, LabelToProbability]
valid_transform = [NormalizeWithMeanStd,Pad,LabelToProbability]
test_transform  = [NormalizeWithMeanStd,Pad]

NormalizeWithMeanStd_channels = [0]
NormalizeWithMeanStd_mean = None
NormalizeWithMeanStd_std  = None
NormalizeWithMeanStd_mask = False
NormalizeWithMeanStd_random_fill = False
NormalizeWithMeanStd_inverse     = False


Pad_output_size = [10, 128, 128]
Pad_ceil_mode   = False
Pad_inverse     = True

RandomCrop_output_size = [10, 128, 128]
RandomCrop_foreground_focus = True
RandomCrop_foreground_ratio = 0.5
Randomcrop_mask_label       = [1, 2]
RandomCrop_inverse     = False

RandomFlip_flip_depth  = False
RandomFlip_flip_height = True
RandomFlip_flip_width  = True
RandomFlip_inverse     = False

LabelToProbability_class_num = 2
LabelToProbability_inverse   = False

[network]
# this section gives parameters for network
# the keys may be different for different networks

# type of network
net_type = UNet2D

# number of class, required for segmentation task
class_num     = 2
in_chns       = 1
feature_chns  = [32, 64, 128, 256, 512]
conv_dims     = [2, 2, 3, 3, 3]
dropout       = [0.0, 0.0, 0.3, 0.4, 0.5]
bilinear      = False
deep_supervise = False

[training]
# list of gpus
gpus = [0]

loss_type     = CrossEntropyLoss
# loss_type     = GeneralizedCELoss
# loss_type     = DiceLoss

# for optimizers
optimizer     = Adam
learning_rate = 1e-2
momentum      = 0.9
weight_decay  = 1e-5

# for lr schedular (MultiStepLR)
lr_scheduler  = ReduceLROnPlateau
lr_gamma      = 0.5
ReduceLROnPlateau_patience = 2000

ckpt_save_dir    = model/unet_cot_vst2s

# start iter
iter_start = 0
iter_max   = 50000
iter_valid = 500
iter_save  = [10000,20000]

[noisy_label_learning]
nll_method   = CoTeaching
co_teaching_select_ratio  = 0.8  
rampup_start = 35000
rampup_end   = 50000
# [noisy_label_learning]
# method_name  = TriNet
# trinet_select_ratio = 0.9
# rampup_start = 1000
# rampup_end   = 8000

[testing]
# list of gpus
gpus       = [0]

# checkpoint mode can be [0-latest, 1-best, 2-specified]
ckpt_mode         = 1
output_dir        = result/unet_cot_vst2s

# convert the label of prediction output
# label_source = [0, 1]
# label_target = [0, 255]